{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST手写字体识别（Neural Networks and Deep Learning）"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "不同网络的构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "def get_train_val(mnist_path):\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data(mnist_path)\n",
    "    print(\"train_images nums:{}\".format(len(train_images)))\n",
    "    print(\"test_images nums:{}\".format(len(test_images)))\n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "def show_mnist(images,labels):\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i],cmap = plt.cm.gray)\n",
    "        plt.xlabel(str(labels[i]))\n",
    "    plt.show()\n",
    "\n",
    "def one_hot(labels):\n",
    "    onehot_labels = np.zeros(shape = [len(labels), 10])\n",
    "    for i in range(len(labels)):\n",
    "        index = labels[i]\n",
    "        onehot_labels[i][index] = 1\n",
    "    return onehot_labels\n",
    "\n",
    "# 构建只含有一个全连接层的网络（使用sigmoid激活函数）\n",
    "def mnist_net(input_shape):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape = input_shape))           \n",
    "    model.add(keras.layers.Dense(units = 100, activation = tf.nn.sigmoid)) \n",
    "    model.add(keras.layers.Dense(units = 10, activation = tf.nn.softmax))\n",
    "    return model\n",
    "\n",
    "# 构建含有一个卷积-池化层的网络（使用sigmoid激活函数）\n",
    "def mnist_cnn(input_shape):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(filters = 20, kernel_size = 5,strides = (1, 1),\n",
    "                                  padding = 'same',activation = tf.nn.sigmoid,input_shape = input_shape))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n",
    "    model.add(keras.layers.Dropout(0.0))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(units = 100, activation = tf.nn.sigmoid))\n",
    "    model.add(keras.layers.Dropout(0.0))\n",
    "    model.add(keras.layers.Dense(units = 10,activation = tf.nn.softmax))\n",
    "    return model\n",
    "\n",
    "# 构建含有两个卷积-池化层的网络（使用sigmoid激活函数）\n",
    "def mnist_cnn2(input_shape):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(filters = 20, kernel_size = 5, strides = (1, 1),\n",
    "                                  padding = 'same', activation = tf.nn.sigmoid,input_shape = input_shape))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n",
    "    model.add(keras.layers.Conv2D(filters = 40, kernel_size = 3, strides = (1, 1), padding = 'same', activation = tf.nn.sigmoid))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n",
    "    model.add(keras.layers.Dropout(0.0))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(units = 100, activation = tf.nn.sigmoid))\n",
    "    model.add(keras.layers.Dropout(0.0))\n",
    "    model.add(keras.layers.Dense(units = 10, activation = tf.nn.softmax))\n",
    "    return model\n",
    "\n",
    "# 构建含有两个卷积-池化层，并使用relu激活函数的网络\n",
    "def mnist_cnn2_relu(input_shape):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(filters = 20, kernel_size = 5, strides = (1, 1),\n",
    "                                  padding = 'same', activation = tf.nn.relu, input_shape = input_shape))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n",
    "    model.add(keras.layers.Conv2D(filters = 40, kernel_size = 3, strides = (1, 1), padding = 'same', activation = tf.nn.relu))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n",
    "    model.add(keras.layers.Dropout(0.0))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(units = 100, activation = tf.nn.relu))\n",
    "    model.add(keras.layers.Dropout(0.0))\n",
    "    model.add(keras.layers.Dense(units = 10, activation = tf.nn.softmax))\n",
    "    return model\n",
    "\n",
    "# 构建含有两个卷积-池化层，两个全连接层的网络（使用relu激活函数）\n",
    "def mnist_cnn2_2f(input_shape):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(filters = 20, kernel_size = 5, strides = (1, 1),\n",
    "                                  padding = 'same', activation = tf.nn.relu, input_shape = input_shape))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n",
    "    model.add(keras.layers.Conv2D(filters = 40, kernel_size = 3, strides = (1, 1), padding = 'same', activation = tf.nn.relu))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n",
    "    model.add(keras.layers.Dropout(0.0))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(units = 100, activation = tf.nn.relu))\n",
    "    model.add(keras.layers.Dropout(0.0))\n",
    "    model.add(keras.layers.Dense(units = 100, activation = tf.nn.relu))\n",
    "    model.add(keras.layers.Dense(units = 10, activation = tf.nn.softmax))\n",
    "    return model\n",
    "\n",
    "# 构建含有两个卷积-池化层，两个全连接层，并使用dropout的网络（使用relu激活函数）\n",
    "def mnist_cnn2_2f_dropout(input_shape):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(filters = 20, kernel_size = 5, strides = (1, 1),\n",
    "                                  padding = 'same', activation = tf.nn.relu, input_shape = input_shape))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n",
    "    model.add(keras.layers.Conv2D(filters = 40, kernel_size = 3, strides = (1, 1), padding = 'same', activation = tf.nn.relu))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n",
    "    model.add(keras.layers.Dropout(0.0))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(units = 1000, activation = tf.nn.relu))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(units = 1000, activation = tf.nn.relu))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(units = 10, activation = tf.nn.softmax))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1、用只含有一个全连接层的网络训练（使用sigmoid激活函数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images nums:60000\n",
      "test_images nums:10000\n",
      "train_images :(60000, 28, 28, 1)\n",
      "test_images :(10000, 28, 28, 1)\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.5011 - acc: 0.8791\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2390 - acc: 0.9322\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.1860 - acc: 0.9470\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.1534 - acc: 0.9557\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1296 - acc: 0.9637\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1113 - acc: 0.9685\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.0965 - acc: 0.9731\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.0842 - acc: 0.9766\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.0740 - acc: 0.9798\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.0659 - acc: 0.9822\n",
      "10000/10000 [==============================] - 0s 40us/sample - loss: 0.0918 - acc: 0.9717\n",
      "Test Accuracy 0.97\n",
      "correct prediction of total : 0.9717\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "def trian_model(train_images, train_labels, test_images, test_labels):\n",
    "    # 将数据转换到0-1之间\n",
    "    train_images = train_images / 255.0 \n",
    "    test_images = test_images / 255.0\n",
    "    \n",
    "    # mnist数据转换为四维\n",
    "    train_images=np.expand_dims(train_images,axis = 3)\n",
    "    test_images=np.expand_dims(test_images,axis = 3)\n",
    "    print(\"train_images :{}\".format(train_images.shape))\n",
    "    print(\"test_images :{}\".format(test_images.shape))\n",
    "\n",
    "    train_labels=one_hot(train_labels)\n",
    "    test_labels=one_hot(test_labels)\n",
    "\n",
    "    # 建立、编译模型\n",
    "    model = mnist_net(input_shape = (28, 28, 1))\n",
    "    model.compile(optimizer = tf.train.AdamOptimizer(), loss = \"categorical_crossentropy\", metrics = ['accuracy'])\n",
    "    model.fit(x = train_images, y = train_labels, epochs = 10, batch_size = 64)\n",
    "    test_loss, test_acc = model.evaluate(x = test_images, y = test_labels)\n",
    "    print(\"Test Accuracy %.2f\" % test_acc)\n",
    "\n",
    "    # 开始训练\n",
    "    cnt = 0\n",
    "    predictions = model.predict(test_images)\n",
    "    for i in range(len(test_images)):\n",
    "        target = np.argmax(predictions[i])\n",
    "        label = np.argmax(test_labels[i])\n",
    "        if target == label:\n",
    "            cnt += 1\n",
    "    print(\"correct prediction of total : %.4f\" % (cnt / len(test_images)))\n",
    "    model.save('mnist-model.h5')\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "    mnist_path = '/data/mnist.npz'\n",
    "    train_images, train_labels, test_images, test_labels = get_train_val(mnist_path)\n",
    "    trian_model(train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "（1）全连接层对提高准确率的辨析：\n",
    "A、全连接层的作用：其相当于一个分类器，能够将学到的“分布式特征表示”映射到样本标记空间。\n",
    "B、全连接层的缺点：参数冗余，可用全局平均池化来代替全连接层来融合学到的深度特征。\n",
    "C、全连接层的优点：在迁移学习中，在源域与目标域差异较大时，全连接层能够保持模型的能力，保证模型表示能够力的迁移，起到了一个“防火墙”的作用。\n",
    "综上，当我们使用迁移模型时，全连接层能够很好的保持模型的能力，对提高准确率有帮助，但是当我们不使用迁移模型时，尽量用全局平均池化来代替全连接层，加快训练过程。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2、用含有一个卷积-池化层的网络训练（使用sigmoid激活函数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images nums:60000\n",
      "test_images nums:10000\n",
      "train_images :(60000, 28, 28, 1)\n",
      "test_images :(10000, 28, 28, 1)\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 56s 938us/sample - loss: 1.2122 - acc: 0.6700\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 59s 978us/sample - loss: 0.3224 - acc: 0.9172\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 58s 966us/sample - loss: 0.2060 - acc: 0.9438\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 58s 965us/sample - loss: 0.1496 - acc: 0.9586\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 58s 967us/sample - loss: 0.1146 - acc: 0.9686\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 58s 967us/sample - loss: 0.0943 - acc: 0.9731 - los\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 58s 974us/sample - loss: 0.0829 - acc: 0.9761\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 59s 976us/sample - loss: 0.0718 - acc: 0.9796\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 59s 978us/sample - loss: 0.0655 - acc: 0.9807\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 59s 976us/sample - loss: 0.0588 - acc: 0.9826: 0s - loss: 0.0590\n",
      "10000/10000 [==============================] - 5s 483us/sample - loss: 0.0628 - acc: 0.9801\n",
      "Test Accuracy 0.98\n",
      "correct prediction of total : 0.9801\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "def trian_model(train_images, train_labels, test_images, test_labels):\n",
    "    train_images = train_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "    \n",
    "    train_images = np.expand_dims(train_images, axis = 3)\n",
    "    test_images = np.expand_dims(test_images, axis = 3)\n",
    "    print(\"train_images :{}\".format(train_images.shape))\n",
    "    print(\"test_images :{}\".format(test_images.shape))\n",
    "\n",
    "    train_labels = one_hot(train_labels)\n",
    "    test_labels = one_hot(test_labels)\n",
    "\n",
    "    model = mnist_cnn(input_shape = (28, 28, 1))\n",
    "    model.compile(optimizer = tf.train.AdamOptimizer(), loss = \"categorical_crossentropy\", metrics = ['accuracy'])\n",
    "    model.fit(x = train_images, y = train_labels, epochs = 10, batch_size = 64)\n",
    "\n",
    "    test_loss,test_acc = model.evaluate(x = test_images,y = test_labels)\n",
    "    print(\"Test Accuracy %.4f\" % test_acc)\n",
    "\n",
    "    cnt = 0\n",
    "    predictions = model.predict(test_images)\n",
    "    for i in range(len(test_images)):\n",
    "        target = np.argmax(predictions[i])\n",
    "        label = np.argmax(test_labels[i])\n",
    "        if target == label:\n",
    "            cnt += 1\n",
    "    print(\"correct prediction of total : %.4f\" % (cnt / len(test_images)))\n",
    "    model.save('mnist-model.h5')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mnist_path = '/data/mnist.npz'\n",
    "    train_images, train_labels, test_images, test_labels = get_train_val(mnist_path)\n",
    "    trian_model(train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3、用含有两个卷积-池化层的网络训练（使用sigmoid激活函数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images nums:60000\n",
      "test_images nums:10000\n",
      "train_images :(60000, 28, 28, 1)\n",
      "test_images :(10000, 28, 28, 1)\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 73s 1ms/sample - loss: 0.8460 - acc: 0.7179\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 75s 1ms/sample - loss: 0.1593 - acc: 0.9539\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 75s 1ms/sample - loss: 0.0926 - acc: 0.9735\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 76s 1ms/sample - loss: 0.0681 - acc: 0.9808\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 75s 1ms/sample - loss: 0.0533 - acc: 0.9844\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 76s 1ms/sample - loss: 0.0443 - acc: 0.9865\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 76s 1ms/sample - loss: 0.0377 - acc: 0.9888\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 76s 1ms/sample - loss: 0.0326 - acc: 0.9903\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 75s 1ms/sample - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 76s 1ms/sample - loss: 0.0238 - acc: 0.9930\n",
      "10000/10000 [==============================] - 6s 592us/sample - loss: 0.0364 - acc: 0.9882\n",
      "Test Accuracy 0.9882\n",
      "correct prediction of total : 0.9882\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "def trian_model(train_images, train_labels, test_images, test_labels):\n",
    "    train_images = train_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    " \n",
    "    train_images = np.expand_dims(train_images,axis = 3)\n",
    "    test_images = np.expand_dims(test_images,axis = 3)\n",
    "    print(\"train_images :{}\".format(train_images.shape))\n",
    "    print(\"test_images :{}\".format(test_images.shape))\n",
    "\n",
    "    train_labels = one_hot(train_labels)\n",
    "    test_labels = one_hot(test_labels)\n",
    "\n",
    "    model = mnist_cnn2(input_shape = (28, 28, 1))\n",
    "    model.compile(optimizer = tf.train.AdamOptimizer(), loss = \"categorical_crossentropy\", metrics = ['accuracy'])\n",
    "    model.fit(x = train_images, y = train_labels, epochs = 10, batch_size = 64)\n",
    "    test_loss, test_acc = model.evaluate(x = test_images, y = test_labels)\n",
    "    print(\"Test Accuracy %.4f\" % test_acc)\n",
    "\n",
    "    cnt = 0\n",
    "    predictions = model.predict(test_images)\n",
    "    for i in range(len(test_images)):\n",
    "        target = np.argmax(predictions[i])\n",
    "        label = np.argmax(test_labels[i])\n",
    "        if target == label:\n",
    "            cnt += 1\n",
    "    print(\"correct prediction of total : %.4f\" % (cnt / len(test_images)))\n",
    "    model.save('mnist-model.h5')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mnist_path = '/data/mnist.npz'\n",
    "    train_images, train_labels, test_images, test_labels = get_train_val(mnist_path)\n",
    "    trian_model(train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "使用两个卷积-池化层能够提取到更多的抽象特征，从而提高准确率。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4、用含有两个卷积-池化层，并使用relu激活函数的网络训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images nums:60000\n",
      "test_images nums:10000\n",
      "train_images :(60000, 28, 28, 1)\n",
      "test_images :(10000, 28, 28, 1)\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 0.1696 - acc: 0.9492\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0498 - acc: 0.9846\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0341 - acc: 0.9892\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0273 - acc: 0.9911\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0196 - acc: 0.9935 0s - loss: 0.0198 - \n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0175 - acc: 0.9940\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0128 - acc: 0.99601s - loss:\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0117 - acc: 0.99635s - l\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0084 - acc: 0.9972\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0092 - acc: 0.9971\n",
      "10000/10000 [==============================] - 6s 554us/sample - loss: 0.0285 - acc: 0.9914\n",
      "Test Accuracy 0.9914\n",
      "correct prediction of total : 0.9914\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "def trian_model(train_images, train_labels, test_images, test_labels):\n",
    "    train_images = train_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "   \n",
    "    train_images = np.expand_dims(train_images,axis = 3)\n",
    "    test_images = np.expand_dims(test_images,axis = 3)\n",
    "    print(\"train_images :{}\".format(train_images.shape))\n",
    "    print(\"test_images :{}\".format(test_images.shape))\n",
    "\n",
    "    train_labels = one_hot(train_labels)\n",
    "    test_labels = one_hot(test_labels)\n",
    "\n",
    "    model = mnist_cnn2_relu(input_shape = (28, 28, 1))\n",
    "    model.compile(optimizer = tf.train.AdamOptimizer(), loss = \"categorical_crossentropy\", metrics = ['accuracy'])\n",
    "    model.fit(x = train_images, y = train_labels, epochs = 10, batch_size = 64)\n",
    "    test_loss,test_acc = model.evaluate(x = test_images, y = test_labels)\n",
    "    print(\"Test Accuracy %.4f\" % test_acc)\n",
    "\n",
    "    cnt = 0\n",
    "    predictions = model.predict(test_images)\n",
    "    for i in range(len(test_images)):\n",
    "        target = np.argmax(predictions[i])\n",
    "        label = np.argmax(test_labels[i])\n",
    "        if target == label:\n",
    "            cnt += 1\n",
    "    print(\"correct prediction of total : %.4f\" % (cnt / len(test_images)))\n",
    "    model.save('mnist-model.h5')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mnist_path = '/data/mnist.npz'\n",
    "    train_images, train_labels, test_images, test_labels = get_train_val(mnist_path)\n",
    "    trian_model(train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "如果我们用tanh激活函数来代替sigmoid激活函数，训练的速度会更快一点，但是最后得到的准确率是差不多的，原因是：\n",
    "A、sigmoid激活函数，导数从0开始，很快就又趋近于0，易造成“梯度消失”现象。\n",
    "B、tanh激活函数是0均值的，有利于提高训练效率。\n",
    "C、模型的激活函数的选取仍然是靠试。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5、用含有两个卷积-池化层，两个全连接层的网络训练（使用relu激活函数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images nums:60000\n",
      "test_images nums:10000\n",
      "train_images :(60000, 28, 28, 1)\n",
      "test_images :(10000, 28, 28, 1)\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 81s 1ms/sample - loss: 0.1781 - acc: 0.9463\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 84s 1ms/sample - loss: 0.0517 - acc: 0.9841\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0369 - acc: 0.9890\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 84s 1ms/sample - loss: 0.0281 - acc: 0.9913\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0230 - acc: 0.9927\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0173 - acc: 0.9942\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0154 - acc: 0.9948\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 84s 1ms/sample - loss: 0.0133 - acc: 0.9957\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 85s 1ms/sample - loss: 0.0119 - acc: 0.9960\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 84s 1ms/sample - loss: 0.0090 - acc: 0.9970\n",
      "10000/10000 [==============================] - 6s 564us/sample - loss: 0.0291 - acc: 0.9917\n",
      "Test Accuracy 0.9917\n",
      "correct prediction of total : 0.9917\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "def trian_model(train_images, train_labels, test_images, test_labels):\n",
    "    train_images = train_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "   \n",
    "    train_images = np.expand_dims(train_images,axis = 3)\n",
    "    test_images = np.expand_dims(test_images,axis = 3)\n",
    "    print(\"train_images :{}\".format(train_images.shape))\n",
    "    print(\"test_images :{}\".format(test_images.shape))\n",
    "\n",
    "    train_labels = one_hot(train_labels)\n",
    "    test_labels = one_hot(test_labels)\n",
    "\n",
    "    model = mnist_cnn2_2f(input_shape = (28, 28, 1))\n",
    "    model.compile(optimizer = tf.train.AdamOptimizer(), loss = \"categorical_crossentropy\", metrics = ['accuracy'])\n",
    "    model.fit(x = train_images, y = train_labels, epochs = 10, batch_size = 64)\n",
    "    test_loss,test_acc = model.evaluate(x = test_images, y = test_labels)\n",
    "    print(\"Test Accuracy %.4f\" % test_acc)\n",
    "\n",
    "    cnt = 0\n",
    "    predictions = model.predict(test_images)\n",
    "    for i in range(len(test_images)):\n",
    "        target = np.argmax(predictions[i])\n",
    "        label = np.argmax(test_labels[i])\n",
    "        if target == label:\n",
    "            cnt += 1\n",
    "    print(\"correct prediction of total : %.4f\" % (cnt / len(test_images)))\n",
    "    model.save('mnist-model.h5')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mnist_path = '/data/mnist.npz'\n",
    "    train_images, train_labels, test_images, test_labels = get_train_val(mnist_path)\n",
    "    trian_model(train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6、用含有两个卷积-池化层、两个全连接层，并使用dropout的网络训练（使用relu激活函数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images nums:60000\n",
      "test_images nums:10000\n",
      "train_images :(60000, 28, 28, 1)\n",
      "test_images :(10000, 28, 28, 1)\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 91s 2ms/sample - loss: 0.1652 - acc: 0.9483\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 91s 2ms/sample - loss: 0.0544 - acc: 0.9835\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 91s 2ms/sample - loss: 0.0397 - acc: 0.9881\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 91s 2ms/sample - loss: 0.0352 - acc: 0.9896\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 91s 2ms/sample - loss: 0.0296 - acc: 0.9912\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 91s 2ms/sample - loss: 0.0227 - acc: 0.9932\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 93s 2ms/sample - loss: 0.0215 - acc: 0.9930\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 91s 2ms/sample - loss: 0.0208 - acc: 0.9942\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 90s 2ms/sample - loss: 0.0183 - acc: 0.9947\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 90s 2ms/sample - loss: 0.0184 - acc: 0.9947\n",
      "10000/10000 [==============================] - 6s 600us/sample - loss: 0.0355 - acc: 0.9914\n",
      "Test Accuracy 0.9914\n",
      "correct prediction of total : 0.9914\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "def trian_model(train_images, train_labels, test_images, test_labels):\n",
    "    train_images = train_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "  \n",
    "    train_images = np.expand_dims(train_images,axis = 3)\n",
    "    test_images = np.expand_dims(test_images,axis = 3)\n",
    "    print(\"train_images :{}\".format(train_images.shape))\n",
    "    print(\"test_images :{}\".format(test_images.shape))\n",
    "\n",
    "    train_labels=one_hot(train_labels)\n",
    "    test_labels=one_hot(test_labels)\n",
    "\n",
    "    model = mnist_cnn2_2f_dropout(input_shape = (28, 28, 1))\n",
    "    model.compile(optimizer = tf.train.AdamOptimizer(), loss = \"categorical_crossentropy\", metrics = ['accuracy'])\n",
    "    model.fit(x = train_images, y = train_labels, epochs = 10, batch_size = 64)\n",
    "    test_loss, test_acc = model.evaluate(x = test_images, y = test_labels)\n",
    "    print(\"Test Accuracy %.4f\" % test_acc)\n",
    "\n",
    "    cnt = 0\n",
    "    predictions = model.predict(test_images)\n",
    "    for i in range(len(test_images)):\n",
    "        target = np.argmax(predictions[i])\n",
    "        label = np.argmax(test_labels[i])\n",
    "        if target == label:\n",
    "            cnt += 1\n",
    "    print(\"correct prediction of total : %.4f\" % (cnt / len(test_images)))\n",
    "    model.save('mnist-model.h5')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mnist_path = '/data/mnist.npz'\n",
    "    train_images, train_labels, test_images, test_labels = get_train_val(mnist_path)\n",
    "    trian_model(train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）在模型中使用dropout的作用？\n",
    "A、能够减少过拟合。\n",
    "B、能够加快训练速度，但是应该在全连接层增加神经元的个数。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "（2）为什么我们只在全连接层中使用dropout？\n",
    "A、卷积层通过权值共享从整幅图中学习特征，从而减少获得局部特征的可能性，避免了过拟合。\n",
    "B、能够训练得更快。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "（3）随着模型层数的增加，产生了梯度消失（爆炸）的问题，解决方法是什么？\n",
    "A、大量使用卷积层，减少参数量。\n",
    "B、使用更加有效的正则化方法（尤其是dropout和卷积层），减少过拟合。\n",
    "C、使用修正的线性单元代替sigmoid，提升训练速度。\n",
    "D、使用GPU训练或者训练更长的时间。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "（4）为什么对输入图片进行变换增加数据集是合理的？\n",
    "A、模型在训练时不会两次查看完全相同的图像，增加样本数量。\n",
    "B、能够观察到数据的更多内容，具有更好的泛化能力。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "（5）卷积神经网络的反向传播模型与全连接神经网络有何不同？\n",
    "A、仍是基本的4个核心公式。\n",
    "B、池化层和卷积层的反向传播公式有所不同。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "对神经网络和深度学习未来的展望：\n",
    "1、有时候用户的表述并不能够正确的想法，未来利用神经网络和深度学习能够挖掘用户模糊输入下的真实目的。\n",
    "2、能够在大数据中发现隐藏的未知信息，在不同的领域带来创新。\n",
    "3、我们对深度学习仍然知之甚少，整个领域大部分仍然靠试，深度学习仍将继续存在。\n",
    "4、AI问题本质上是一个科学问题而不是一个工程问题，知识的结构塑造了科学的社会结构，但是科学的社会结构反过来限制和促进我们所能得到的知识。\n",
    "5、从使用深度学习到实现一个真正的AI，我们仍有很长的路要走。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
